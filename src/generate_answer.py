from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage
from typing import List, Dict


def get_friendly_name(collection_name: str) -> str:
    return collection_name


def generate_answer(self, query: str, search_results: List[Dict], openai_api_key: str):
    if not search_results:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    if not openai_api_key:
        return "OpenAI API keyê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

    print(f"\n-------- ë‹µë³€ ìƒì„± ì‹œì‘ --------")
    print(f"ì§ˆë¬¸: '{query}'")
    print(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(search_results)}")

    # ë³´í—˜ì‚¬ë³„ ê·¸ë£¹í™” ë° context ìƒì„±
    company_results = {}
    for result in search_results:
        collection_name = result.get("collection", "")
        company_results.setdefault(collection_name, []).append(result)

    multiple_companies = len(company_results) > 1
    is_comparison = any(
        kw in query.lower()
        for kw in [
            "ë¹„êµ",
            "ì°¨ì´",
            "ë‹¤ë¥¸",
            "ë‹¤ë¥¸ì ",
            "ë¹„êµí•´",
            "ë¹„êµí•´ì¤˜",
            "ì°¨ì´ì ",
            "ì•Œë ¤ì¤˜",
            "ë­ê°€ ë” ë‚˜ì€ê°€",
        ]
    )

    context = ""
    for company, results in company_results.items():
        friendly_name = get_friendly_name(company)
        company_context = ""
        if multiple_companies:
            company_context += f"\n\n## {friendly_name} ì •ë³´:\n"
        for result in results:
            text = result.get("metadata", {}).get("text", "")
            if text:
                company_context += f"\n---\n{text}"
        context += company_context

    if not context.strip():
        return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±
    system_prompt = "You are an insurance policy expert. Always answer in Korean."
    if multiple_companies and is_comparison:
        system_prompt += " ì—¬ëŸ¬ ë³´í—˜ì‚¬ì˜ ì•½ê´€ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ì°¨ì´ì ê³¼ ê³µí†µì ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."

    print(f"ğŸ§  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: {system_prompt[:80]}...")
    print(f"ğŸ“„ ë¬¸ë§¥ ê¸¸ì´: {len(context)}")

    # LCEL ìŠ¤íƒ€ì¼ ì²´ì¸ êµ¬ì„±
    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessage(content=system_prompt),
            ("human", "ì§ˆë¬¸: {query}\n\nê´€ë ¨ ë¬¸ì„œ: {context}\n\në‹µë³€:"),
        ]
    )

    llm = ChatOpenAI(
        model="gpt-4o-mini", api_key=openai_api_key, temperature=0.7, max_tokens=2000
    )

    # LCEL í‘œí˜„: prompt â†’ llm
    chain: Runnable = prompt | llm

    # ì‹¤í–‰
    print("ğŸ” LLM ì‘ë‹µ ìƒì„± ì¤‘...")
    response = chain.invoke({"query": query, "context": context})

    answer = response.content
    print(f"âœ… ì‘ë‹µ ì™„ë£Œ (ê¸¸ì´: {len(answer)} ì)")
    print(f"-------- ë‹µë³€ ìƒì„± ì™„ë£Œ --------\n")
    return answer
